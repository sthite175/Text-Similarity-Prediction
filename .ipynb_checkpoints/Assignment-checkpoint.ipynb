{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b900425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from contractions import fix\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer, LancasterStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.util import ngrams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dcb840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"DataNeuron_Text_Similarity.csv\")\n",
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d17e764d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>broadband challenges tv viewing the number of ...</td>\n",
       "      <td>gardener wins double in glasgow britain s jaso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap boss arrested over drug find rap mogul mar...</td>\n",
       "      <td>amnesty chief laments war failure the lack of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player burn-out worries robinson england coach...</td>\n",
       "      <td>hanks greeted at wintry premiere hollywood sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hearts of oak 3-2 cotonsport hearts of oak set...</td>\n",
       "      <td>redford s vision of sundance despite sporting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir paul rocks super bowl crowds sir paul mcca...</td>\n",
       "      <td>mauresmo opens with victory in la amelie maure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>uk directors guild nominees named martin scors...</td>\n",
       "      <td>steel firm  to cut  45 000 jobs mittal steel  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>u2 to play at grammy awards show irish rock ba...</td>\n",
       "      <td>israel looks to us for bank chief israel has a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>pountney handed ban and fine northampton coach...</td>\n",
       "      <td>india and iran in gas export deal india has si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>belle named  best scottish band  belle &amp; sebas...</td>\n",
       "      <td>mido makes third apology ahmed  mido  hossam h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>criminal probe on citigroup deals traders at u...</td>\n",
       "      <td>former ni minister scott dies former northern ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text1  \\\n",
       "0     broadband challenges tv viewing the number of ...   \n",
       "1     rap boss arrested over drug find rap mogul mar...   \n",
       "2     player burn-out worries robinson england coach...   \n",
       "3     hearts of oak 3-2 cotonsport hearts of oak set...   \n",
       "4     sir paul rocks super bowl crowds sir paul mcca...   \n",
       "...                                                 ...   \n",
       "2995  uk directors guild nominees named martin scors...   \n",
       "2996  u2 to play at grammy awards show irish rock ba...   \n",
       "2997  pountney handed ban and fine northampton coach...   \n",
       "2998  belle named  best scottish band  belle & sebas...   \n",
       "2999  criminal probe on citigroup deals traders at u...   \n",
       "\n",
       "                                                  text2  \n",
       "0     gardener wins double in glasgow britain s jaso...  \n",
       "1     amnesty chief laments war failure the lack of ...  \n",
       "2     hanks greeted at wintry premiere hollywood sta...  \n",
       "3     redford s vision of sundance despite sporting ...  \n",
       "4     mauresmo opens with victory in la amelie maure...  \n",
       "...                                                 ...  \n",
       "2995  steel firm  to cut  45 000 jobs mittal steel  ...  \n",
       "2996  israel looks to us for bank chief israel has a...  \n",
       "2997  india and iran in gas export deal india has si...  \n",
       "2998  mido makes third apology ahmed  mido  hossam h...  \n",
       "2999  former ni minister scott dies former northern ...  \n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ba2e4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'broadband challenges tv viewing the number of europeans with broadband has exploded over the past 12 months  with the web eating into tv viewing habits  research suggests.  just over 54 million people are hooked up to the net via broadband  up from 34 million a year ago  according to market analysts nielsen/netratings. the total number of people online in europe has broken the 100 million mark. the popularity of the net has meant that many are turning away from tv  say analysts jupiter research. it found that a quarter of web users said they spent less time watching tv in favour of the net  the report by nielsen/netratings found that the number of people with fast internet access had risen by 60% over the past year.  the biggest jump was in italy  where it rose by 120%. britain was close behind  with broadband users almost doubling in a year. the growth has been fuelled by lower prices and a wider choice of always-on  fast-net subscription plans.  twelve months ago high speed internet users made up just over one third of the audience in europe; now they are more than 50% and we expect this number to keep growing   said gabrielle prior  nielsen/netratings analyst.  as the number of high-speed surfers grows  websites will need to adapt  update and enhance their content to retain their visitors and encourage new ones.  the total number of europeans online rose by 12% to 100 million over the past year  the report showed  with the biggest rise in france  italy  britain and germany.  the ability to browse web pages at high speed  download files such as music or films and play online games is changing what people do in their spare time.  a study by analysts jupiter research suggested that broadband was challenging television viewing habits. in homes with broadband  40% said they were spending less time watching tv. the threat to tv was greatest in countries where broadband was on the up  in particular the uk  france and spain  said the report. it said tv companies faced a major long-term threat over the next five years  with broadband predicted to grow from 19% to 37% of households by 2009.  year-on-year we are continuing to see a seismic shift in where  when and how europe s population consume media for information and entertainment and this has big implications for tv  newspaper and radio   said jupiter research analyst olivier beauvillian.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fa1ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_blank(data):\n",
    "    clean_text = data.replace(\"\\\\n\",\" \").replace(\"\\t\",\" \")\n",
    "    return clean_text\n",
    "\n",
    "def expand_text(data):\n",
    "    clean_text = fix(data)\n",
    "    return clean_text\n",
    "\n",
    "stopword_list = stopwords.words(\"english\")\n",
    "stopword_list.remove(\"no\")\n",
    "stopword_list.remove(\"nor\")\n",
    "stopword_list.remove(\"not\")\n",
    "\n",
    "def clean_text(data):\n",
    "    tokens = word_tokenize(data)\n",
    "    clean_data = [word.lower() for word in tokens if (word.lower() not in punctuation) and (word.lower() not in stopword_list) and ( len(word)>2) and (word.isalpha()) ]\n",
    "    return clean_data\n",
    "\n",
    "def lemmatization(data):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    final_text = []\n",
    "    for word in data:\n",
    "        lemmatized_word = lemmatizer.lemmatize(word)\n",
    "        final_text.append(lemmatized_word)\n",
    "    return final_text#\" \".join(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82bb94d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>New_text1</th>\n",
       "      <th>New_text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>broadband challenges tv viewing the number of ...</td>\n",
       "      <td>gardener wins double in glasgow britain s jaso...</td>\n",
       "      <td>[broadband, challenge, viewing, number, europe...</td>\n",
       "      <td>[gardener, win, double, glasgow, britain, jaso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap boss arrested over drug find rap mogul mar...</td>\n",
       "      <td>amnesty chief laments war failure the lack of ...</td>\n",
       "      <td>[rap, bos, arrested, drug, find, rap, mogul, m...</td>\n",
       "      <td>[amnesty, chief, lament, war, failure, lack, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player burn-out worries robinson england coach...</td>\n",
       "      <td>hanks greeted at wintry premiere hollywood sta...</td>\n",
       "      <td>[player, worry, robinson, england, coach, andy...</td>\n",
       "      <td>[hank, greeted, wintry, premiere, hollywood, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hearts of oak 3-2 cotonsport hearts of oak set...</td>\n",
       "      <td>redford s vision of sundance despite sporting ...</td>\n",
       "      <td>[heart, oak, cotonsport, heart, oak, set, ghan...</td>\n",
       "      <td>[redford, vision, sundance, despite, sporting,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir paul rocks super bowl crowds sir paul mcca...</td>\n",
       "      <td>mauresmo opens with victory in la amelie maure...</td>\n",
       "      <td>[sir, paul, rock, super, bowl, crowd, sir, pau...</td>\n",
       "      <td>[mauresmo, open, victory, amelie, mauresmo, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>uk directors guild nominees named martin scors...</td>\n",
       "      <td>steel firm  to cut  45 000 jobs mittal steel  ...</td>\n",
       "      <td>[director, guild, nominee, named, martin, scor...</td>\n",
       "      <td>[steel, firm, cut, job, mittal, steel, one, wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>u2 to play at grammy awards show irish rock ba...</td>\n",
       "      <td>israel looks to us for bank chief israel has a...</td>\n",
       "      <td>[play, grammy, award, show, irish, rock, band,...</td>\n",
       "      <td>[israel, look, bank, chief, israel, asked, ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>pountney handed ban and fine northampton coach...</td>\n",
       "      <td>india and iran in gas export deal india has si...</td>\n",
       "      <td>[pountney, handed, ban, fine, northampton, coa...</td>\n",
       "      <td>[india, iran, gas, export, deal, india, signed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>belle named  best scottish band  belle &amp; sebas...</td>\n",
       "      <td>mido makes third apology ahmed  mido  hossam h...</td>\n",
       "      <td>[belle, named, best, scottish, band, belle, se...</td>\n",
       "      <td>[mido, make, third, apology, ahmed, mido, hoss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>criminal probe on citigroup deals traders at u...</td>\n",
       "      <td>former ni minister scott dies former northern ...</td>\n",
       "      <td>[criminal, probe, citigroup, deal, trader, ban...</td>\n",
       "      <td>[former, minister, scott, dy, former, northern...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text1  \\\n",
       "0     broadband challenges tv viewing the number of ...   \n",
       "1     rap boss arrested over drug find rap mogul mar...   \n",
       "2     player burn-out worries robinson england coach...   \n",
       "3     hearts of oak 3-2 cotonsport hearts of oak set...   \n",
       "4     sir paul rocks super bowl crowds sir paul mcca...   \n",
       "...                                                 ...   \n",
       "2995  uk directors guild nominees named martin scors...   \n",
       "2996  u2 to play at grammy awards show irish rock ba...   \n",
       "2997  pountney handed ban and fine northampton coach...   \n",
       "2998  belle named  best scottish band  belle & sebas...   \n",
       "2999  criminal probe on citigroup deals traders at u...   \n",
       "\n",
       "                                                  text2  \\\n",
       "0     gardener wins double in glasgow britain s jaso...   \n",
       "1     amnesty chief laments war failure the lack of ...   \n",
       "2     hanks greeted at wintry premiere hollywood sta...   \n",
       "3     redford s vision of sundance despite sporting ...   \n",
       "4     mauresmo opens with victory in la amelie maure...   \n",
       "...                                                 ...   \n",
       "2995  steel firm  to cut  45 000 jobs mittal steel  ...   \n",
       "2996  israel looks to us for bank chief israel has a...   \n",
       "2997  india and iran in gas export deal india has si...   \n",
       "2998  mido makes third apology ahmed  mido  hossam h...   \n",
       "2999  former ni minister scott dies former northern ...   \n",
       "\n",
       "                                              New_text1  \\\n",
       "0     [broadband, challenge, viewing, number, europe...   \n",
       "1     [rap, bos, arrested, drug, find, rap, mogul, m...   \n",
       "2     [player, worry, robinson, england, coach, andy...   \n",
       "3     [heart, oak, cotonsport, heart, oak, set, ghan...   \n",
       "4     [sir, paul, rock, super, bowl, crowd, sir, pau...   \n",
       "...                                                 ...   \n",
       "2995  [director, guild, nominee, named, martin, scor...   \n",
       "2996  [play, grammy, award, show, irish, rock, band,...   \n",
       "2997  [pountney, handed, ban, fine, northampton, coa...   \n",
       "2998  [belle, named, best, scottish, band, belle, se...   \n",
       "2999  [criminal, probe, citigroup, deal, trader, ban...   \n",
       "\n",
       "                                              New_text2  \n",
       "0     [gardener, win, double, glasgow, britain, jaso...  \n",
       "1     [amnesty, chief, lament, war, failure, lack, p...  \n",
       "2     [hank, greeted, wintry, premiere, hollywood, s...  \n",
       "3     [redford, vision, sundance, despite, sporting,...  \n",
       "4     [mauresmo, open, victory, amelie, mauresmo, ma...  \n",
       "...                                                 ...  \n",
       "2995  [steel, firm, cut, job, mittal, steel, one, wo...  \n",
       "2996  [israel, look, bank, chief, israel, asked, ban...  \n",
       "2997  [india, iran, gas, export, deal, india, signed...  \n",
       "2998  [mido, make, third, apology, ahmed, mido, hoss...  \n",
       "2999  [former, minister, scott, dy, former, northern...  \n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['New_text1'] = df['text1'].apply(remove_blank)\n",
    "df['New_text1'] = df['New_text1'].apply(expand_text)\n",
    "df['New_text1'] = df['New_text1'].apply(clean_text)\n",
    "df['New_text1'] = df['New_text1'].apply(lemmatization)\n",
    "\n",
    "\n",
    "df['New_text2'] = df['text2'].apply(remove_blank)\n",
    "df['New_text2'] = df['New_text2'].apply(expand_text)\n",
    "df['New_text2'] = df['New_text2'].apply(clean_text)\n",
    "df['New_text2'] = df['New_text2'].apply(lemmatization)\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519dcc30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b27da7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>New_text1</th>\n",
       "      <th>New_text2</th>\n",
       "      <th>Token_len_Text1</th>\n",
       "      <th>Token_len_Text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>broadband challenges tv viewing the number of ...</td>\n",
       "      <td>gardener wins double in glasgow britain s jaso...</td>\n",
       "      <td>[broadband, challenge, viewing, number, europe...</td>\n",
       "      <td>[gardener, win, double, glasgow, britain, jaso...</td>\n",
       "      <td>211</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap boss arrested over drug find rap mogul mar...</td>\n",
       "      <td>amnesty chief laments war failure the lack of ...</td>\n",
       "      <td>[rap, bos, arrested, drug, find, rap, mogul, m...</td>\n",
       "      <td>[amnesty, chief, lament, war, failure, lack, p...</td>\n",
       "      <td>133</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player burn-out worries robinson england coach...</td>\n",
       "      <td>hanks greeted at wintry premiere hollywood sta...</td>\n",
       "      <td>[player, worry, robinson, england, coach, andy...</td>\n",
       "      <td>[hank, greeted, wintry, premiere, hollywood, s...</td>\n",
       "      <td>133</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hearts of oak 3-2 cotonsport hearts of oak set...</td>\n",
       "      <td>redford s vision of sundance despite sporting ...</td>\n",
       "      <td>[heart, oak, cotonsport, heart, oak, set, ghan...</td>\n",
       "      <td>[redford, vision, sundance, despite, sporting,...</td>\n",
       "      <td>157</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir paul rocks super bowl crowds sir paul mcca...</td>\n",
       "      <td>mauresmo opens with victory in la amelie maure...</td>\n",
       "      <td>[sir, paul, rock, super, bowl, crowd, sir, pau...</td>\n",
       "      <td>[mauresmo, open, victory, amelie, mauresmo, ma...</td>\n",
       "      <td>229</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>uk directors guild nominees named martin scors...</td>\n",
       "      <td>steel firm  to cut  45 000 jobs mittal steel  ...</td>\n",
       "      <td>[director, guild, nominee, named, martin, scor...</td>\n",
       "      <td>[steel, firm, cut, job, mittal, steel, one, wo...</td>\n",
       "      <td>162</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>u2 to play at grammy awards show irish rock ba...</td>\n",
       "      <td>israel looks to us for bank chief israel has a...</td>\n",
       "      <td>[play, grammy, award, show, irish, rock, band,...</td>\n",
       "      <td>[israel, look, bank, chief, israel, asked, ban...</td>\n",
       "      <td>112</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>pountney handed ban and fine northampton coach...</td>\n",
       "      <td>india and iran in gas export deal india has si...</td>\n",
       "      <td>[pountney, handed, ban, fine, northampton, coa...</td>\n",
       "      <td>[india, iran, gas, export, deal, india, signed...</td>\n",
       "      <td>78</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>belle named  best scottish band  belle &amp; sebas...</td>\n",
       "      <td>mido makes third apology ahmed  mido  hossam h...</td>\n",
       "      <td>[belle, named, best, scottish, band, belle, se...</td>\n",
       "      <td>[mido, make, third, apology, ahmed, mido, hoss...</td>\n",
       "      <td>174</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>criminal probe on citigroup deals traders at u...</td>\n",
       "      <td>former ni minister scott dies former northern ...</td>\n",
       "      <td>[criminal, probe, citigroup, deal, trader, ban...</td>\n",
       "      <td>[former, minister, scott, dy, former, northern...</td>\n",
       "      <td>154</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text1  \\\n",
       "0     broadband challenges tv viewing the number of ...   \n",
       "1     rap boss arrested over drug find rap mogul mar...   \n",
       "2     player burn-out worries robinson england coach...   \n",
       "3     hearts of oak 3-2 cotonsport hearts of oak set...   \n",
       "4     sir paul rocks super bowl crowds sir paul mcca...   \n",
       "...                                                 ...   \n",
       "2995  uk directors guild nominees named martin scors...   \n",
       "2996  u2 to play at grammy awards show irish rock ba...   \n",
       "2997  pountney handed ban and fine northampton coach...   \n",
       "2998  belle named  best scottish band  belle & sebas...   \n",
       "2999  criminal probe on citigroup deals traders at u...   \n",
       "\n",
       "                                                  text2  \\\n",
       "0     gardener wins double in glasgow britain s jaso...   \n",
       "1     amnesty chief laments war failure the lack of ...   \n",
       "2     hanks greeted at wintry premiere hollywood sta...   \n",
       "3     redford s vision of sundance despite sporting ...   \n",
       "4     mauresmo opens with victory in la amelie maure...   \n",
       "...                                                 ...   \n",
       "2995  steel firm  to cut  45 000 jobs mittal steel  ...   \n",
       "2996  israel looks to us for bank chief israel has a...   \n",
       "2997  india and iran in gas export deal india has si...   \n",
       "2998  mido makes third apology ahmed  mido  hossam h...   \n",
       "2999  former ni minister scott dies former northern ...   \n",
       "\n",
       "                                              New_text1  \\\n",
       "0     [broadband, challenge, viewing, number, europe...   \n",
       "1     [rap, bos, arrested, drug, find, rap, mogul, m...   \n",
       "2     [player, worry, robinson, england, coach, andy...   \n",
       "3     [heart, oak, cotonsport, heart, oak, set, ghan...   \n",
       "4     [sir, paul, rock, super, bowl, crowd, sir, pau...   \n",
       "...                                                 ...   \n",
       "2995  [director, guild, nominee, named, martin, scor...   \n",
       "2996  [play, grammy, award, show, irish, rock, band,...   \n",
       "2997  [pountney, handed, ban, fine, northampton, coa...   \n",
       "2998  [belle, named, best, scottish, band, belle, se...   \n",
       "2999  [criminal, probe, citigroup, deal, trader, ban...   \n",
       "\n",
       "                                              New_text2  Token_len_Text1  \\\n",
       "0     [gardener, win, double, glasgow, britain, jaso...              211   \n",
       "1     [amnesty, chief, lament, war, failure, lack, p...              133   \n",
       "2     [hank, greeted, wintry, premiere, hollywood, s...              133   \n",
       "3     [redford, vision, sundance, despite, sporting,...              157   \n",
       "4     [mauresmo, open, victory, amelie, mauresmo, ma...              229   \n",
       "...                                                 ...              ...   \n",
       "2995  [steel, firm, cut, job, mittal, steel, one, wo...              162   \n",
       "2996  [israel, look, bank, chief, israel, asked, ban...              112   \n",
       "2997  [india, iran, gas, export, deal, india, signed...               78   \n",
       "2998  [mido, make, third, apology, ahmed, mido, hoss...              174   \n",
       "2999  [former, minister, scott, dy, former, northern...              154   \n",
       "\n",
       "      Token_len_Text2  \n",
       "0                 278  \n",
       "1                 273  \n",
       "2                 131  \n",
       "3                 257  \n",
       "4                 194  \n",
       "...               ...  \n",
       "2995              148  \n",
       "2996              139  \n",
       "2997              147  \n",
       "2998              192  \n",
       "2999              185  \n",
       "\n",
       "[3000 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Token_len_Text1'] = df.New_text1.apply(lambda x: len(x))\n",
    "df['Token_len_Text2'] = df.New_text2.apply(lambda x: len(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0f8b83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1610\n",
      "62\n",
      "--------------------------\n",
      "2160\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "print(df['Token_len_Text1'].max())\n",
    "print(df['Token_len_Text1'].min())\n",
    "print(\"--------------------------\")\n",
    "print(df['Token_len_Text2'].max())\n",
    "print(df['Token_len_Text2'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de26a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['New_text1'] = df['text1'].apply(remove_blank)\n",
    "df['New_text1'] = df['New_text1'].apply(expand_text)\n",
    "df['New_text1'] = df['New_text1'].apply(clean_text)\n",
    "df['New_text1'] = df['New_text1'].apply(lemmatization)\n",
    "\n",
    "\n",
    "df['New_text2'] = df['text2'].apply(remove_blank)\n",
    "df['New_text2'] = df['New_text2'].apply(expand_text)\n",
    "df['New_text2'] = df['New_text2'].apply(clean_text)\n",
    "df['New_text2'] = df['New_text2'].apply(lemmatization)\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f75d68ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(df['text1'][0].split())  = 403\n",
    "#df['text1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "faf557e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a[0]\n",
    "d = ['I love programming language',\n",
    "    'i like data science',\n",
    "    'we are reading text from board']\n",
    "\n",
    "doc1 = df1['text1'][0]    # doc1 type is >> str\n",
    "doc2 = df1['text2'][0]\n",
    "doc = (doc1,doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "252485b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdbd5ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x414 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 455 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = CountVectorizer()\n",
    "c = count.fit_transform(doc)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7d5f0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57e94786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  0,  2,  1,  0,  0,  0,  1,  0,  0,  1,  0,  0,  0,  0,  1,\n",
       "         1,  0,  1,  0,  0,  0,  1,  0,  1,  1,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  1,  0,  0,  1,  1,  1,  0,  0,  0,  2,  0,  0,  1,  0,\n",
       "         1,  0,  2,  3, 11,  0,  0,  4,  2,  1,  0,  1,  1,  0,  0,  1,\n",
       "         1,  1,  0,  0,  1,  2,  0,  0,  0,  2,  0,  8,  1,  1,  0,  0,\n",
       "         7,  0,  0,  1,  1,  0,  0,  0,  1,  1,  0,  0,  0,  0,  0,  1,\n",
       "         0,  0,  0,  1,  0,  0,  1,  1,  1,  0,  1,  0,  0,  0,  0,  1,\n",
       "         0,  1,  0,  1,  1,  0,  1,  0,  1,  0,  1,  3,  2,  0,  0,  1,\n",
       "         0,  1,  1,  0,  2,  1,  0,  0,  1,  1,  0,  0,  0,  0,  0,  1,\n",
       "         2,  2,  0,  2,  3,  1,  0,  1,  1,  0,  1,  0,  0,  0,  0,  0,\n",
       "         1,  0,  1,  1,  1,  1,  2,  1,  0,  5,  0,  0,  0,  3,  0,  0,\n",
       "         0,  0,  1,  1,  0,  1,  1,  0,  1,  0, 11,  0,  1,  0,  0,  2,\n",
       "         1,  0,  0,  1,  3,  2,  0,  0,  0,  0,  0,  1,  3,  2,  0,  1,\n",
       "         0,  0,  0,  0,  0,  0,  2,  1,  0,  1,  0,  1,  0,  1,  0,  1,\n",
       "         1,  0,  1,  0,  0,  0,  1,  1,  0,  0,  0,  4,  0,  2,  1,  0,\n",
       "         1,  0,  1,  0,  4,  3,  1,  1,  1,  0,  3,  0,  1,  6, 11,  0,\n",
       "         0,  0,  0,  1,  0,  0,  3,  1,  1,  3,  1,  0,  0,  6,  1,  1,\n",
       "         3,  4,  0,  0,  0,  1,  1,  0,  0,  0,  0,  0,  1,  1,  1,  1,\n",
       "         1,  0,  1,  0,  0,  1,  0,  0,  0,  0,  0,  3,  4,  1,  1,  1,\n",
       "         2,  0,  0,  0,  6,  0,  1,  0,  0,  0,  0,  1,  1,  0,  0,  0,\n",
       "         0,  0,  0,  0,  1,  0,  0,  1,  0,  0,  0,  0,  1,  1,  3,  1,\n",
       "         1,  0,  0,  0,  1,  1,  0,  1,  0,  1,  1,  0,  1,  0,  0,  1,\n",
       "         1,  1,  4, 26,  3,  0,  0,  3,  0,  1,  2,  2,  3,  0, 11,  0,\n",
       "         0,  2,  0,  0,  1,  8,  1,  1,  0,  0,  0,  4,  1,  3,  0,  0,\n",
       "         0,  0,  1,  0,  3,  1,  5,  2,  0,  2,  3,  1,  0,  1,  1,  1,\n",
       "         3,  0,  1,  1,  0,  0,  0,  7,  0,  0,  0,  6,  1,  0],\n",
       "       [ 0,  1,  0,  0,  1,  2,  1,  0,  1,  1,  0,  2,  1,  1,  1,  0,\n",
       "         0,  1,  0,  2,  1,  2,  0,  1,  0,  0,  4,  1,  1,  1,  1,  2,\n",
       "         1,  1,  0,  1,  1,  0,  0,  0,  1,  1,  1,  0,  2,  1,  0,  1,\n",
       "         0,  1,  0,  0, 12,  1,  1,  0,  8,  2,  2,  0,  0,  1,  2,  0,\n",
       "         0,  1,  1,  2,  0,  0,  1,  1,  1, 11,  1,  0,  0,  0,  1,  1,\n",
       "         1,  1,  1,  0,  0,  3,  1,  1,  0,  0,  1,  1,  1,  1,  1,  0,\n",
       "         1,  1,  1,  0,  1,  1,  0,  0,  0,  1,  0,  1,  1,  1,  1,  0,\n",
       "         3,  0,  1,  0,  0,  1,  0,  1,  0,  1,  0,  0,  0,  1,  1,  0,\n",
       "         1,  0,  0,  1,  0,  0,  1,  1,  0,  0,  2,  1,  1,  3,  1,  0,\n",
       "         7,  0,  5,  5,  2,  0,  1,  0,  0,  3,  0,  2,  2,  2,  1,  1,\n",
       "         0,  1,  0,  0,  0,  0,  0,  1,  1,  0,  3,  1,  2,  1,  3,  1,\n",
       "         1,  2,  0,  0,  1,  0,  0,  1,  0,  1, 20,  2,  0,  1,  1,  0,\n",
       "         1,  1,  1,  0,  2,  2,  1,  1,  1,  2,  1,  3,  0,  1,  1,  0,\n",
       "         1,  1,  2,  1,  1,  1,  0,  1,  1,  0,  1,  0,  1,  1,  1,  0,\n",
       "         1,  1,  0,  1,  1,  1,  0,  0,  1,  5,  1,  0,  1,  1,  0,  1,\n",
       "         0,  1,  0,  1,  0,  0,  2,  0,  1,  2,  0,  1,  0,  0, 15,  2,\n",
       "         1,  1,  1,  0,  3,  1,  3,  1,  0,  0,  0,  3,  1,  1,  0,  0,\n",
       "         0,  0,  2,  1,  2,  0,  0,  1,  1,  3,  1,  1,  0,  0,  0,  0,\n",
       "         0,  1,  0,  1,  6,  0,  4,  1,  1,  3,  1,  0,  0,  0,  0,  0,\n",
       "         0,  1,  6,  1,  1,  1,  0,  1,  1,  3,  1,  0,  0,  1,  1,  1,\n",
       "         1,  1,  1,  1,  0,  1,  1,  0,  2,  1,  1,  1,  0,  0,  0,  0,\n",
       "         0,  1,  1,  1,  0,  0,  2,  0,  1,  0,  0,  1,  0,  2,  3,  0,\n",
       "         0,  0,  0, 32,  1,  1,  4,  0,  1,  4,  2,  0,  0,  1, 13,  2,\n",
       "         1,  1,  1,  1,  0,  0,  0,  0,  1,  1,  1,  1,  0,  0,  1,  1,\n",
       "         1,  3,  0,  5,  0,  0,  8,  0,  1,  0,  0,  0,  3,  1,  1,  1,\n",
       "         0,  2,  0,  0,  3,  1,  1, 10,  4,  6,  3,  1,  0,  1]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "899350ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c.A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c106f205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68525568]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(c[0],c[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e57e7b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x414 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 200 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b938a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b948ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_blank(data):\n",
    "    clean_text = data.replace(\"\\\\n\",\" \").replace(\"\\t\",\" \")\n",
    "    return clean_text\n",
    "\n",
    "def expand_text(data):\n",
    "    clean_text = fix(data)\n",
    "    return clean_text\n",
    "\n",
    "stopword_list = stopwords.words(\"english\")\n",
    "stopword_list.remove(\"no\")\n",
    "stopword_list.remove(\"nor\")\n",
    "stopword_list.remove(\"not\")\n",
    "\n",
    "def clean_text(data):\n",
    "    tokens = word_tokenize(data)\n",
    "    clean_data = [word.lower() for word in tokens if (word.lower() not in punctuation) and (word.lower() not in stopword_list) and ( len(word)>2) and (word.isalpha()) ]\n",
    "    return clean_data\n",
    "\n",
    "def lemmatization(data):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    final_text = []\n",
    "    for word in data:\n",
    "        lemmatized_word = lemmatizer.lemmatize(word)\n",
    "        final_text.append(lemmatized_word)\n",
    "    return \" \".join(final_text)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"DataNeuron_Text_Similarity.csv\")\n",
    "\n",
    "df['New_text1'] = df['text1'].apply(remove_blank)\n",
    "df['New_text1'] = df['New_text1'].apply(expand_text)\n",
    "df['New_text1'] = df['New_text1'].apply(clean_text)\n",
    "df['New_text1'] = df['New_text1'].apply(lemmatization)\n",
    "\n",
    "\n",
    "df['New_text2'] = df['text2'].apply(remove_blank)\n",
    "df['New_text2'] = df['New_text2'].apply(expand_text)\n",
    "df['New_text2'] = df['New_text2'].apply(clean_text)\n",
    "df['New_text2'] = df['New_text2'].apply(lemmatization)\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20696259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e7ade5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
